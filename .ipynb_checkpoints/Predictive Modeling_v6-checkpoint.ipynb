{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(PM.10) Predictive modeling is one of the main topics of data mining and can range from correlation to supervised segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "        \n",
       "        function resizeIframe(ifrm) {       \n",
       "            ifrm.style.height = ifrm.contentWindow.document.body.scrollHeight + 'px';\n",
       "            // Setting the width here, or setting overflowX to \"hidden\" as above both \n",
       "            // work for this page. It may be that one turns out to be better.\n",
       "            ifrm.style.width = ifrm.contentWindow.document.body.scrollWidth + 'px';\n",
       "        }\n",
       "        \n",
       "        function code_toggle(identifier) {\n",
       "        \n",
       "            code_cell = $( \"span:contains(\" + identifier + \"):last\" ).parentsUntil('div.cell').last().parent().next().children().first();\n",
       "            \n",
       "            if ($(code_cell).is(':visible')) {\n",
       "            code_cell.hide();\n",
       "            }\n",
       "            else\n",
       "            {\n",
       "            code_cell.show();\n",
       "            }\n",
       "            \n",
       "            var ifrm = window.parent.document.getElementById('ipython_notebook_frame');   \n",
       "            setTimeout(resizeIframe, 0, ifrm);\n",
       "        \n",
       "        }\n",
       "        \n",
       "        function hide_all() {\n",
       "             $('div.input').hide();\n",
       "        }\n",
       "\n",
       "        $( document ).ready(hide_all);\n",
       "         \n",
       "        \n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Global Functions\n",
    "import init\n",
    "from IPython.display import HTML\n",
    "\n",
    "def scriptHTML():\n",
    "    script = '''\n",
    "        <script>\n",
    "        \n",
    "        function resizeIframe(ifrm) {       \n",
    "            ifrm.style.height = ifrm.contentWindow.document.body.scrollHeight + 'px';\n",
    "            // Setting the width here, or setting overflowX to \"hidden\" as above both \n",
    "            // work for this page. It may be that one turns out to be better.\n",
    "            ifrm.style.width = ifrm.contentWindow.document.body.scrollWidth + 'px';\n",
    "        }\n",
    "        \n",
    "        function code_toggle(identifier) {\n",
    "        \n",
    "            code_cell = $( \"span:contains(\" + identifier + \"):last\" ).parentsUntil('div.cell').last().parent().next().children().first();\n",
    "            \n",
    "            if ($(code_cell).is(':visible')) {\n",
    "            code_cell.hide();\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "            code_cell.show();\n",
    "            }\n",
    "            \n",
    "            var ifrm = window.parent.document.getElementById('ipython_notebook_frame');   \n",
    "            setTimeout(resizeIframe, 0, ifrm);\n",
    "        \n",
    "        }\n",
    "        \n",
    "        function hide_all() {\n",
    "             $('div.input').hide();\n",
    "        }\n",
    "\n",
    "        $( document ).ready(hide_all);\n",
    "         \n",
    "        \n",
    "        </script>\n",
    "        '''\n",
    "    \n",
    "    return HTML(script)\n",
    "\n",
    "def hide_code_message(identifier,message=\"Show/Hide Code\"):\n",
    "    form_start1 = ''' <form action=\\\"javascript:code_toggle('''\n",
    "    identifier = \"'\" + identifier +  \"'\"\n",
    "    form_start2 = ''')\\\"> <input type=\\\"submit\\\" value= '''\n",
    "    form_end = '''></form>'''\n",
    "    \n",
    "    #print (form_start1 + identifier + form_start2 + '\"' + message + '\"' + form_end)\n",
    "    return HTML(form_start1 + identifier + form_start2 + '\"' + message + '\"' + form_end)\n",
    "\n",
    "scriptHTML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <form action=\"javascript:code_toggle('code-SS.10')\"> <input type=\"submit\" value= \"Show/Hide Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-SS.10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hide_input": false,
    "hide_output": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>80s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lord of the Rings 3</td>\n",
       "      <td>00s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>90s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Average</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>90s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inception</td>\n",
       "      <td>10s</td>\n",
       "      <td>Action</td>\n",
       "      <td>Average</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>70s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Average</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aliens</td>\n",
       "      <td>80s</td>\n",
       "      <td>Horror</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once upon a time in America</td>\n",
       "      <td>80s</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Long</td>\n",
       "      <td>Average</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title Year   Genre   Length   Rating Watched\n",
       "0      Raiders of the Lost Ark  80s  Action  Average  Average     Yes\n",
       "1      The Lord of the Rings 3  00s   Drama     Long     High     Yes\n",
       "2                   Fight Club  90s   Drama  Average     High     Yes\n",
       "3                   Braveheart  90s   Drama     Long  Average     Yes\n",
       "4                    Inception  10s  Action  Average     High      No\n",
       "5                The Godfather  70s   Drama  Average     High      No\n",
       "6                       Aliens  80s  Horror  Average  Average      No\n",
       "7  Once upon a time in America  80s   Crime     Long  Average      No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display movie history dataset\n",
    "import init\n",
    "import plotly\n",
    "import plotly.tools as tls\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import cufflinks as cf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "movie_history = pd.read_csv('https://goo.gl/xRfbvH')\n",
    "display(movie_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <form action=\"javascript:code_toggle('code-MID.10')\"> <input type=\"submit\" value= \"Show/Hide Code that calculates entropy\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-MID.10\",\"Show/Hide Code that calculates entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.10) The first concept within predictive modeling is supervised segmentation. Consider this example of a movie subscription service, like netflix, where there is a movie database that contains the history of whether a person watched a movie or not. Based on this history, we would like to predict which movie out of a potential list of unwatched movies, the person is likely to watch in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.20) So the target variable that we are interested in from the history is called *Watched*, which is a Yes or No value that represents whether the person watched a movie. Figuring out how we can find a formula, or in other words ***segment*** the history dataset to result in the value of *Watched = Yes*, is an example of supervised segmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.30) Additionally, in this case we are talking about predicting a Yes or No value for the target variable *Watched*, which means we are doing a ***classification***. If we were predicting a numeric value such as the likelihood of watching a movie, instead of a Yes or No value, then we would be doing a ***regression***. In other words, a regression is to predict a numeric value for a target variable of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.40) The first part of supervised segmentation is to select the important informative attributes. The attributes we have in this dataset are *Title*,*Year*, *Genre*, *Length* and *Rating*. A single row of atrribute-values represent what is called a Feature vector. As an example, a feature vector here is: [ Title: The Godfather, Year : 70s, Genre: Drama, Length: Average, Rating: High ]. Each value in the feature vector is called a feature value. The attribute *Watched?* is the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.50) So what is an informative attribute? An informative attribute is something that reduces uncertainity about the target variable. Let's assume for a second that we perfectly understand the person's preferences. The person prefers the drama genre over others, but the length of the movie doesn't matter to the person. In this case the *Genre* attribute is more informative, as in it reduces the uncertainity of predicting whether the person will watch a movie or not. However the *Length* attribute is not informative because, in this case, it doesn't contribute to reducing the uncertainty of whether or not the person will watch a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Models, induction and deduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(MID.10) We need a systematic mechanism or *Model* in order to figure out which attributes are informative. The process of creating models from data is called **Induction** and the procedure that creates a model from the data is called a *learner* or an *induction algorithm*. Induction essentially refers to generalizing from a specific case to general rules. We use the process of induction to create models from training data, which in this case is the movie dataset and then use *deduction* to use the model to predict target values for other instances of feature vectors, which in this case is the list of unwatched movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(MID.20) Now let's try to create a model to figure out which attributes are more informative than others. The first concept is to quantify the randomness of the dataset for the target variable. To quantify the randomness of the dataset we use a concept called entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(MID.30) Entropy is a measure of probability or relative percentage of each unique value occuring among all values in a dataset . Entropy is defined by the following mathematical formula:\n",
    "$$entropy = - p_1 log (p_1) - p_2 log (p_2) - ...$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculates the entropy of the given data set for the target attribute.\n",
    "def entropy(data, target_attr):\n",
    " \n",
    "    val_freq = {}\n",
    "    data_entropy = 0.0\n",
    " \n",
    "    # Calculate the frequency of each of the values in the target attr\n",
    "    for record in data:\n",
    "        \n",
    "        if (record[target_attr] in val_freq):\n",
    "            val_freq[record[target_attr]] += 1.0\n",
    "        else:\n",
    "            val_freq[record[target_attr]]  = 1.0\n",
    " \n",
    "    # Calculate the entropy of the data for the target attribute\n",
    "    for freq in val_freq.values():\n",
    "        data_entropy += (-freq/len(data)) * math.log(freq/len(data), 2) \n",
    " \n",
    "    return round(data_entropy,2)\n",
    "\n",
    "def calc_entropy(criteria,target, message):    \n",
    "    print (message,entropy(movie_history[criteria].to_dict('records'),target))    \n",
    "    return entropy(movie_history[criteria].to_dict('records'),target)\n",
    "\n",
    "no_filter = calc_entropy(criteria=movie_history.index >= 0,target='Watched',message=\"Entropy of dataset:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "(MID.40) Where $p_1$, in this example, is the probability of the target variable *Watched = Yes* and $p_2$ is the probability of the target variable *Watched = No* in the result set. Simply looking at this formula tells us that if all records had values of *Watched = Yes*, then $p_1 = 1 and p_2 = 0$ and therefore $log (p_1) = 0 $ which makes the entropy equal 0. A segment with an entropy of 0 denotes a **pure** segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <form action=\"javascript:code_toggle('code-MID.40')\"> <input type=\"submit\" value= \"Show/Hide Code that generates the entropy plot\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-MID.40\",\"Show/Hide Code that generates the entropy plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hide_input": true,
    "hide_output": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cloaked/125.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot entropy concept\n",
    "data = [{'Watched': 'No'},\n",
    " {'Watched': 'No'},\n",
    " {'Watched': 'No'},\n",
    " {'Watched': 'No'},\n",
    " {'Watched': 'No'},\n",
    " {'Watched': 'No'},\n",
    " {'Watched': 'No'},\n",
    " {'Watched': 'No'}]\n",
    "\n",
    "\n",
    "def target_values(d):\n",
    "    vals = \"\"\n",
    "    for i in range(0,len(data)):\n",
    "        if i != 0:\n",
    "            vals = vals + \",\"\n",
    "        if i == len(data)/2:\n",
    "            vals = vals + \"<br>\"\n",
    "        vals = vals + d[i]['Watched']\n",
    "    return vals\n",
    "\n",
    "last_index = len(data) \n",
    "entropies = pd.DataFrame(columns=('X','Y','label'))\n",
    "   \n",
    "for i in range(0,last_index):        \n",
    "    entropies.loc[i]= [i,entropy(data,\"Watched\"),target_values(data)]\n",
    "    data[i]['Watched'] = 'Yes' \n",
    "entropies.loc[i+1]= [i+1,entropy(data,\"Watched\"),target_values(data)]\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=entropies.X,\n",
    "    y=entropies.Y,\n",
    "    mode='lines+markers+text',\n",
    "    name='Lines, Markers and Text',\n",
    "    text= entropies.label\n",
    ")\n",
    "\n",
    "display_data = [trace1]\n",
    "layout = go.Layout(\n",
    "    title = \n",
    "    'Entropy variation with the set of target values of <i>Watched</i> changing from all <b>No</b> to all <b>Yes</b> within the dataset',\n",
    "    showlegend=False, font=dict(family='Source Sans Pro')\n",
    ")\n",
    "fig = go.Figure(data=display_data, layout=layout)\n",
    "\n",
    "py.iplot(fig,filename='entropy_concept')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "(MID.50) When you take the movie dataset of 8 rows and plot the entropy assuming all movies are unwatched, which means an entropy of 0, to assuming all movies are watched, which also means an entropy of 0, we find that the entropy is the highest at the midpoint where 50% of the movies are watched and 50% of movies are unwatched, which is the point of maximum randomness. Hence entropy helps us measure the general disorder of the segmentation which is an indicator that could be used to quantify how much a particular attribute increases or decreases the disorder of the segmentation produced. To increase the predictability of the segmentation, we want to indentify attributes that decrease the randomness of the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lord of the Rings 3</td>\n",
       "      <td>00s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>90s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Average</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>90s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>70s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Average</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title Year  Genre   Length   Rating Watched\n",
       "1  The Lord of the Rings 3  00s  Drama     Long     High     Yes\n",
       "2               Fight Club  90s  Drama  Average     High     Yes\n",
       "3               Braveheart  90s  Drama     Long  Average     Yes\n",
       "5            The Godfather  70s  Drama  Average     High      No"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_history[movie_history.Genre.str.contains('Drama')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "(MID.60) In order to mathematically identify how much an attribute decreases randomness over the whole segmentation it creates, we use a concept called information gain that builds on the concept of entropy. \n",
    "To understand this better, lets filter this dataset by the attribute *Genre*. Looking at the movie history data, we see *Genre* has one of 4 values : Action, Drama, Horror, Crime. If we were to filter the history dataset by *Genre = Drama*, we would get 3 Watched movies and 1 unwatched movie and a resulting entropy of ~0.81. This entropy is less than the entropy of the whole dataset which was 1.0. Hence the information gain for a particular attrbute is derived as some function of change in entropy when the dataset is filtered or split on that attribute. When we plot the information gain for the attributes in the movie history dataset, we get the information gain values as 0.66, 0.34, 0.05, 0 for Year, Genre, Length and Rating respectively, showing that Year of the movie is the most informative attribute to predict whether a movie will be watched, followed by Genre and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <form action=\"javascript:code_toggle('code-MID.50')\"> <input type=\"submit\" value= \"Show/Hide Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-MID.50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy when Genre=Drama: 0.81\n"
     ]
    }
   ],
   "source": [
    "genre_entropy = calc_entropy(criteria=movie_history.Genre.str.contains('Drama'),target='Watched',message=\"Entropy when Genre=Drama:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cloaked/127.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-MID.60\",\"Show/Hide Code to generate Information gain plot\")\n",
    "\n",
    "#Code to plot information gain\n",
    "# Calculates the information gain (reduction in entropy) \n",
    "#that would result by splitting the data on the chosen attribute (attr).\n",
    "def gain(data, attr, target_attr):\n",
    " \n",
    "    val_freq = {}\n",
    "    subset_entropy = 0.0\n",
    " \n",
    "    # Calculate the frequency of each of the values in the target attribute\n",
    "    for record in data:\n",
    "        if (record[attr] in val_freq):\n",
    "            val_freq[record[attr]] += 1.0\n",
    "        else:\n",
    "            val_freq[record[attr]]  = 1.0\n",
    " \n",
    "    # Calculate the sum of the entropy for each subset of records weighted by \n",
    "    #their probability of occuring in the training set.\n",
    "    for val in val_freq.keys():\n",
    "        val_prob = val_freq[val] / sum(val_freq.values())\n",
    "        data_subset = [record for record in data if record[attr] == val]\n",
    "        subset_entropy += val_prob * entropy(data_subset, target_attr)\n",
    " \n",
    "    # Subtract the entropy of the chosen attribute from the entropy of the whole\n",
    "    #data set with respect to the target attribute (and return it)\n",
    "    return round((entropy(data, target_attr) - subset_entropy),2)\n",
    " \n",
    "\n",
    "def calc_information_gain(criteria,attr,target):        \n",
    "    return gain(movie_history[criteria].to_dict('records'),attr, target)\n",
    "\n",
    "\n",
    "target_variable = 'Watched'\n",
    "gains = pd.DataFrame(columns=('Attribute','Gain'))\n",
    "for i in range (0,len(movie_history.columns)):\n",
    "    gains.loc[i]= [movie_history.columns.values[i],\n",
    "                   calc_information_gain(movie_history.index >= 0,\n",
    "                     movie_history.columns.values[i],target_variable)]\n",
    "\n",
    "#Exclude target variable\n",
    "gains = (gains[gains.Attribute.str.find(target_variable) == -1])  \n",
    "gains = (gains[gains.Attribute.str.find('Title') == -1])    \n",
    "trace1 = go.Bar(\n",
    "    x=gains.Attribute,\n",
    "    y=gains.Gain,\n",
    "    text=gains.Gain    \n",
    ")\n",
    "\n",
    "display_data = [trace1]\n",
    "layout = go.Layout(\n",
    "    title = \n",
    "    'Information gain by attribute',\n",
    "    showlegend=False, font=dict(family='Source Sans Pro')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=display_data, layout=layout)\n",
    "\n",
    "py.iplot(fig,filename='information_gain_concept')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(DT.10) Finding the most informative attribute alone is likely insufficient to produce segments that are predictive of target values. There is an elegant mechanism to combine multiple informative attributes to produce supervised segmentation for the target variable. This mechanism is called a decision tree. Decision trees are often used as predictive models. When presented with an example for which we don't know a classification, we can predict it's classification by traversing the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(DT.15) Decision trees are an important concept due to their ability to learn to classify individual records in a dataset. They are used in many areas, from typical marketing scenarios such as targeting to airplane autopilots and medical diagnoses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(DT.20) Using concepts we just learnt, let us build a decision tree model for our Movie subscription service to help us predict which movie out of a potential list of unwatched movies, the person is likely to watch in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(DT.30) Creating a decision tree starts with choosing the most informative attribute in the dataset. This attribute becomes a **node** in the tree. For every value of this attribute, a child node is created. So, in our example, the most informative attribute is *Year*, and *Year* becomes our first node. *Year* has  possible values : 70s, 80s, 90s, 00s, 10s and a child node is created for each of these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"align=middle\" src=\"ipyimages/decision_tree1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "(DT.40) When we flter the dataset with the value at a node, we either get a pure dataset, which means all target values are the same at this node, or we get an impure dataset. If the dataset is pure, then this node is a leaf node. If the dataset is impure then the tree is built again at this node by picking the next best attribute. The process continues recursively till we reach all leaf nodes and this creates the decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"align=middle\" src=\"ipyimages/decision_tree.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <form action=\"javascript:code_toggle('code-DT.50')\"> <input type=\"submit\" value= \"Show/Hide code that creates the decision tree\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-DT.50\",\"Show/Hide code that creates the decision tree\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     18
    ],
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "def choose_attribute(data_input, attributes, target_attr):\n",
    "    \"\"\" Cycles through all the attributes and returns the attribute with the\n",
    "    highest information gain \"\"\"\n",
    "\n",
    "    data = data_input[:]\n",
    "    best_gain = 0.0\n",
    "    best_attr = None\n",
    "\n",
    "    for attr in attributes:\n",
    "        if attr != target_attr:\n",
    "            gain1 = gain(data, attr, target_attr)\n",
    "            if gain1 > best_gain:\n",
    "                best_gain = gain1\n",
    "                best_attr = attr\n",
    "    \n",
    "    return best_attr\n",
    "\n",
    "def majority_value(data, target_attr):\n",
    "    \n",
    "    dic = {}\n",
    "    max_item = \"\"\n",
    "    for record in data:\n",
    "        dic[record[target_attr]] = dic.get(record[target_attr], 0) + 1\n",
    "    counts = [(j,i) for i,j in dic.items()]\n",
    "    count, max_item = max(counts)\n",
    "    del dic\n",
    "    return max_item\n",
    "\n",
    "def get_subset( data_input, best, val):\n",
    "    \"\"\" Returns a list of all the records in data with the value of attribute\n",
    "    matching the given value \"\"\"\n",
    "\n",
    "    data = data_input[:]\n",
    "    list = []\n",
    "\n",
    "    if not data:\n",
    "        return list\n",
    "    else:\n",
    "        for record in data:\n",
    "            if record[best] == val:\n",
    "                list.append(record)\n",
    "        return list\n",
    "\n",
    "\n",
    "def create_decision_tree(data_input, attributes, target_attr,attributes_only=False):\n",
    "    \"\"\" Returns a new decision tree \"\"\"\n",
    "    #print (\"--------------\")\n",
    "    #print (\"\\n\")\n",
    "    \n",
    "    #display (data_input)\n",
    "    #display (attributes)\n",
    "    \n",
    "    \n",
    "    data    = data_input[:]\n",
    "    vals    = [record[target_attr] for record in data]\n",
    "    default = majority_value(data, target_attr)\n",
    "\n",
    "    # If the dataset or attributes is empty, return the default value. Subtract\n",
    "    # 1 to account for target attributes\n",
    "    if not data or (len(attributes) - 1) <= 0:        \n",
    "        return default\n",
    "    # If all the records in dataset have the same values, return it\n",
    "    elif vals.count(vals[0]) == len(vals):\n",
    "        #print (\"same values\")\n",
    "        return vals[0]\n",
    "    else:\n",
    "        # Choose the next best attribute\n",
    "        best_attr = choose_attribute(data, attributes, target_attr)\n",
    "        if (attributes_only):\n",
    "            print (best_attr)\n",
    "            \n",
    "        # Create a new tree/node with the best attribute\n",
    "        tree = {best_attr:{}}\n",
    "        \n",
    "        #print (best_attr)\n",
    "\n",
    "        # Preprocess data, to generate a list containing the same data as data list\n",
    "        # but without duplicate\n",
    "\n",
    "        unique_data = []\n",
    "        for record in data:\n",
    "            if unique_data.count(record[best_attr]) <= 0:\n",
    "                unique_data.append(record[best_attr])\n",
    "\n",
    "        # Create a new decision tree for each of the values in the best\n",
    "        # attribute field\n",
    "        for val in unique_data:\n",
    "            # Create a subtree for the current value under the best field\n",
    "            subtree = create_decision_tree(\n",
    "                    get_subset(data, best_attr, val),\n",
    "                    [attr for attr in attributes if attr != best_attr],\n",
    "                    target_attr, attributes_only\n",
    "                    )\n",
    "\n",
    "            # Add the new subtree to the empty dictionary\n",
    "            tree[best_attr][val] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "attributes = movie_history.columns.tolist()\n",
    "attributes.remove('Watched')\n",
    "attributes.remove('Title')\n",
    "\n",
    "def print_tree(tree,string):\n",
    "    if type(tree) == dict:\n",
    "        print (list(tree.keys())[0],\"--->\")        \n",
    "        for item in list(tree.values())[0].keys():\n",
    "            #print ('***begin***')\n",
    "            print (string + \"\\t\\t\",item,':', end=\"\")                          \n",
    "            print_tree(list(tree.values())[0][item], string + \"\\t\")\n",
    "            #print ('***end***')\n",
    "    else:\n",
    "        #print ('else part')\n",
    "        print (tree)        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year --->\n",
      "\t\t 80s :Genre --->\n",
      "\t\t\t Horror :No\n",
      "\t\t\t Action :Yes\n",
      "\t\t\t Crime :No\n",
      "\t\t 00s :Yes\n",
      "\t\t 90s :Genre --->\n",
      "\t\t\t Sci-Fi :Yes\n",
      "\t\t\t Drama :Yes\n",
      "\t\t\t Comedy :Yes\n",
      "\t\t\t Action :No\n",
      "\t\t\t Crime :Length --->\n",
      "\t\t\t\t Average :Yes\n",
      "\t\t\t\t Long :Yes\n",
      "\t\t 70s :No\n",
      "\t\t 10s :No\n",
      "\t\t 60s :No\n"
     ]
    }
   ],
   "source": [
    "movie_history2 = pd.read_csv('https://goo.gl/ZdIl1w')\n",
    "tree=create_decision_tree(movie_history2.to_dict('records'),attributes,target_variable)        \n",
    "print_tree(tree, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(DT.60) Let us use our decision tree classifier built in python to classify the following three examples using our decision tree learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <form action=\"javascript:code_toggle('code-DT.60')\"> <input type=\"submit\" value= \"Show/Hide Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-DT.60\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Classification: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reservoir Dogs</td>\n",
       "      <td>90s</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apocalypse Now</td>\n",
       "      <td>70s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>Average</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>90s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>Average</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title Year  Genre   Length   Rating Watched\n",
       "0  Reservoir Dogs  90s  Crime  Average  Average       ?\n",
       "1  Apocalypse Now  70s  Drama     Long  Average       ?\n",
       "2      Braveheart  90s  Drama     Long  Average       ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Classification: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reservoir Dogs</td>\n",
       "      <td>90s</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apocalypse Now</td>\n",
       "      <td>70s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>Average</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>90s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Long</td>\n",
       "      <td>Average</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title Year  Genre   Length   Rating Watched\n",
       "0  Reservoir Dogs  90s  Crime  Average  Average     Yes\n",
       "1  Apocalypse Now  70s  Drama     Long  Average      No\n",
       "2      Braveheart  90s  Drama     Long  Average     Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "Year --->\n",
      "\t\t 80s :Genre --->\n",
      "\t\t\t Horror :No\n",
      "\t\t\t Action :Yes\n",
      "\t\t\t Crime :No\n",
      "\t\t 00s :Yes\n",
      "\t\t 90s :Genre --->\n",
      "\t\t\t Sci-Fi :Yes\n",
      "\t\t\t Drama :Yes\n",
      "\t\t\t Comedy :Yes\n",
      "\t\t\t Action :No\n",
      "\t\t\t Crime :Length --->\n",
      "\t\t\t\t Average :Yes\n",
      "\t\t\t\t Long :Yes\n",
      "\t\t 70s :No\n",
      "\t\t 10s :No\n",
      "\t\t 60s :No\n"
     ]
    }
   ],
   "source": [
    "def classifier(tree, instance, default_class=None):\n",
    "    '''Returns a classification label for instance, given a decision tree'''\n",
    "    if not tree:  # if the node is empty, return the default class\n",
    "        return default_class\n",
    "    if not isinstance(tree, dict):  # if the node is a leaf, return its class label\n",
    "        return tree\n",
    "    attribute_index = list(tree.keys())[0]  # using list(dict.keys()) for Python 3 compatibility\n",
    "    attribute_values = list(tree.values())[0]\n",
    "    instance_attribute_value = instance[attribute_index]\n",
    "    if instance_attribute_value not in attribute_values:  # this value was not in training data\n",
    "        return default_class\n",
    "    # recursively traverse the subtree (branch) associated with instance_attribute_value\n",
    "    return classifier(attribute_values[instance_attribute_value], instance, default_class)     \n",
    "\n",
    "\n",
    "def classify(examples):\n",
    "    for i in range(0,len(examples)):        \n",
    "        examples.Watched[i] = classifier(tree,examples.to_dict('records')[i])    \n",
    "    return examples\n",
    "\n",
    "#Examples to classify\n",
    "examples = pd.read_csv('https://goo.gl/RFVTGk')\n",
    "print (\"Before Classification: \")\n",
    "display(examples)\n",
    "print (\"After Classification: \")\n",
    "display(classify(examples))\n",
    "print(\"Decision Tree:\")\n",
    "print_tree(tree, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <form action=\"javascript:code_toggle('code-DT.70')\"> <input type=\"submit\" value= \"Show/Hide Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_code_message(\"code-DT.70\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(DT.70) When we have our learner classify 3 examples, we get 2 movies classified as Yes and one movie classified as No. Let's validate one result by traversing the decision tree. The first record is Reservoir Dogs, with *Year = 90s*. When we look at 90s in the decision tree, there is no pure result and hence the tree points us to look at *Genre*. The Genre for Reservoir Dogs is Crime, and when we look at Crime under Genre in the decision tree, again there is no pure result and the tree now points us to look at Length. The length of the movie Reservoir dogs is Average, and when we look at the decision tree we are at the leaf node, with a pure result of Yes, which matches the output from our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "(DT.80) Tree-structured models work very well, though they may not be the most accurate model one can produce from a particular data set. This brings us to the end of this video where we talked about entropy, information gain and how they can ultimately be used within decision trees to create a learner out of a labeled dataset."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
