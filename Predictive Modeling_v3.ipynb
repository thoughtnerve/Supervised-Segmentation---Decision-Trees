{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Predictive modeling is one of the main topics of data mining and can range from correlation to supervised segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "code_folding": [
     12
    ],
    "collapsed": false,
    "hide_input": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>1981</td>\n",
       "      <td>Action, Adventure</td>\n",
       "      <td>1h 55min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lord of the Rings 3</td>\n",
       "      <td>2003</td>\n",
       "      <td>Adventure, Drama</td>\n",
       "      <td>3h 21min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2h 19min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>1995</td>\n",
       "      <td>Biography, Drama</td>\n",
       "      <td>2h 58min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>Action, Mystery, Sci-Fi</td>\n",
       "      <td>2h 28 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>2h 55min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aliens</td>\n",
       "      <td>1986</td>\n",
       "      <td>Action, Horror, Sci-Fi</td>\n",
       "      <td>2h 17min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once upon a time in America</td>\n",
       "      <td>1984</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>3h 49min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  Year                    Genre     Length  \\\n",
       "0      Raiders of the Lost Ark  1981        Action, Adventure   1h 55min   \n",
       "1      The Lord of the Rings 3  2003         Adventure, Drama   3h 21min   \n",
       "2                   Fight Club  1999                    Drama   2h 19min   \n",
       "3                   Braveheart  1995         Biography, Drama   2h 58min   \n",
       "4                    Inception  2010  Action, Mystery, Sci-Fi  2h 28 min   \n",
       "5                The Godfather  1972             Crime, Drama   2h 55min   \n",
       "6                       Aliens  1986   Action, Horror, Sci-Fi   2h 17min   \n",
       "7  Once upon a time in America  1984             Crime, Drama   3h 49min   \n",
       "\n",
       "   Rating Watched  \n",
       "0     8.5     Yes  \n",
       "1     8.9     Yes  \n",
       "2     8.9     Yes  \n",
       "3     8.4     Yes  \n",
       "4     8.8      No  \n",
       "5     9.2      No  \n",
       "6     8.4      No  \n",
       "7     8.4      No  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import python_libraries\n",
    "import plotly\n",
    "import plotly.tools as tls\n",
    "from IPython.display import display\n",
    "import cufflinks as cf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# Calculates the entropy of the given data set for the target attribute.\n",
    "def entropy(data, target_attr):\n",
    " \n",
    "    val_freq = {}\n",
    "    data_entropy = 0.0\n",
    " \n",
    "    # Calculate the frequency of each of the values in the target attr\n",
    "    for record in data:\n",
    "        \n",
    "        if (record[target_attr] in val_freq):\n",
    "            val_freq[record[target_attr]] += 1.0\n",
    "        else:\n",
    "            val_freq[record[target_attr]]  = 1.0\n",
    " \n",
    "    # Calculate the entropy of the data for the target attribute\n",
    "    for freq in val_freq.values():\n",
    "        data_entropy += (-freq/len(data)) * math.log(freq/len(data), 2) \n",
    " \n",
    "    return round(data_entropy,2)\n",
    "\n",
    "\n",
    "def calc_entropy(criteria,target):    \n",
    "    print (\"Entropy (Randomness): \" +  str(entropy(movie_history[criteria].to_dict('records'),target)))\n",
    "    display (movie_history[criteria])\n",
    "    return entropy(movie_history[criteria].to_dict('records'),target)\n",
    "\n",
    "\n",
    "py.sign_in('cloaked', 'wiwoxbjrvr')\n",
    "#plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "movie_history = pd.read_csv('https://docs.google.com/spreadsheets/d/1fJ0DKxFkMr2XjzyspZFLv6yOlHJvl639Qpap0O4U78E/pub?gid=0&single=true&output=csv')\n",
    "movie_history.head(len(movie_history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.10) The first concept within predictive modeling is supervised segmentation. Consider this example of a movie subscription service, like netflix, where there is a movie database that contains the history of whether a person watched a movie or not. Based on this history, we would like to predict which movie out of a potential list of unwatched movies, the person is likely to watch in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.20) So the target variable that we are interested in from the history is called *Watched*, which is a Yes or No value that represents whether the person watched a movie. Figuring out how we can find a formula, or in other words ***segment*** the history dataset to result in the value of *Watched = Yes*, is an example of supervised segmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.30) Additionally, in this case we are talking about predicting a Yes or No value for the target variable *Watched*, which means we are doing a ***classification***. If we were predicting a numeric value such as the likelihood of watching a movie, instead of a Yes or No value, then we would be doing a ***regression***. In other words, a regression is to predict a numeric value for a target variable of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.50) So what is an informative attribute? An informative attribute is something that reduces uncertainity about the target variable. Let's for assume for a second that we perfectly understand the person's preferences. The person prefers the drama genre over others, but the length of the movie doesn't matter to the person. In this case the *Genre* attribute is more informative, as in it reduces the uncertainity of predicting whether the person will watch a movie or not. However the *Length* attribute is not informative because, in this case, it doesn't contribute to reducing the uncertainty of whether or not the person will watch a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(SS.40) The first part of supervised segmentation is to select the important informative attributes. The attributes we have in this dataset are *Title*,*Year*, *Genre*, *Length* and *Rating*. A single row of atrribute-values represent what is called a Feature vector. As an example, a feature vector here is: [ Title: The Godfather, Year : 1972, Genre: Crime/Drama, Length: 2h 55min, Rating: 9.2 ]. Each value in the feature vector is called a feature value. The attribute *Watched?* is the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Models, induction and deduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(MID.10) We need a systematic mechanism or *Model* in order to figure out which attributes are informative. The process of creating models from data is called **Induction** and the procedure that creates a model from the data is called a *learner* or an *induction algorithm*. Induction essentially refers to generalizing from a specific case to general rules. We use the process of induction to create models from training data, which in this case is the movie dataset and then use *deduction* to use the model to predict target values for other instances of feature vectors, which in this case is the list of unwatched movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full list with no attribute s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (Randomness): 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>1981</td>\n",
       "      <td>Action, Adventure</td>\n",
       "      <td>1h 55min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lord of the Rings 3</td>\n",
       "      <td>2003</td>\n",
       "      <td>Adventure, Drama</td>\n",
       "      <td>3h 21min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2h 19min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>1995</td>\n",
       "      <td>Biography, Drama</td>\n",
       "      <td>2h 58min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>Action, Mystery, Sci-Fi</td>\n",
       "      <td>2h 28 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>2h 55min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aliens</td>\n",
       "      <td>1986</td>\n",
       "      <td>Action, Horror, Sci-Fi</td>\n",
       "      <td>2h 17min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once upon a time / America</td>\n",
       "      <td>1984</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>3h 49min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Title  Year                    Genre     Length  \\\n",
       "0     Raiders of the Lost Ark  1981        Action, Adventure   1h 55min   \n",
       "1     The Lord of the Rings 3  2003         Adventure, Drama   3h 21min   \n",
       "2                  Fight Club  1999                    Drama   2h 19min   \n",
       "3                  Braveheart  1995         Biography, Drama   2h 58min   \n",
       "4                   Inception  2010  Action, Mystery, Sci-Fi  2h 28 min   \n",
       "5               The Godfather  1972             Crime, Drama   2h 55min   \n",
       "6                      Aliens  1986   Action, Horror, Sci-Fi   2h 17min   \n",
       "7  Once upon a time / America  1984             Crime, Drama   3h 49min   \n",
       "\n",
       "   Rating Watched  \n",
       "0     8.5     Yes  \n",
       "1     8.9     Yes  \n",
       "2     8.9     Yes  \n",
       "3     8.4     Yes  \n",
       "4     8.8      No  \n",
       "5     9.2      No  \n",
       "6     8.4      No  \n",
       "7     8.4      No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_filter = calc_entropy(criteria=movie_history.index >= 0,target='Watched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(MID.20) Now let's try to create a model to figure out which attributes are more informative than others. Let's start with Genre. When we filter the history by Genre = Drama we get 3 watched movies and 2 unwatched movies, which is a highly random result. If we would have got a result of 5 watched movies or 5 unwatched movies, then the result would have been non random or **pure**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (Randomness): 0.97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lord of the Rings 3</td>\n",
       "      <td>2003</td>\n",
       "      <td>Adventure, Drama</td>\n",
       "      <td>3h 21min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2h 19min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>1995</td>\n",
       "      <td>Biography, Drama</td>\n",
       "      <td>2h 58min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>2h 55min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once upon a time / America</td>\n",
       "      <td>1984</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>3h 49min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Title  Year             Genre    Length  Rating  \\\n",
       "1     The Lord of the Rings 3  2003  Adventure, Drama  3h 21min     8.9   \n",
       "2                  Fight Club  1999             Drama  2h 19min     8.9   \n",
       "3                  Braveheart  1995  Biography, Drama  2h 58min     8.4   \n",
       "5               The Godfather  1972      Crime, Drama  2h 55min     9.2   \n",
       "7  Once upon a time / America  1984      Crime, Drama  3h 49min     8.4   \n",
       "\n",
       "  Watched  \n",
       "1     Yes  \n",
       "2     Yes  \n",
       "3     Yes  \n",
       "5      No  \n",
       "7      No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genre_filter = calc_entropy(criteria=movie_history.Genre.str.contains('Drama'),target='Watched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(MID.30) To quantify the randomness of the result we use a concept called entropy. In this example the value of entropy is 0.97 and is defined by the following mathematical formula:\n",
    "$$entropy = - p_1 log (p_1) - p_2 log (p_2) - ...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(MID.40) Where $p_1$, in this example, is the probability of the target variable *Watched = Yes* and $p_2$ is the probability of the target variable *Watched = No* in the result set. Simply looking at this formula tells us that if all resulting values had *Watched = Yes*, then $p_1 = 1 and p_2 = 0$ and therefore $log (p_1) = 0 $ which makes the entropy equal 0. Hence an entropy of 0 denotes the least randomness, while an entropy of 1 means the most randomness. Let's see a couple of more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (Randomness): 0.92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lord of the Rings 3</td>\n",
       "      <td>2003</td>\n",
       "      <td>Adventure, Drama</td>\n",
       "      <td>3h 21min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2h 19min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>2h 55min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title  Year             Genre    Length  Rating Watched\n",
       "1  The Lord of the Rings 3  2003  Adventure, Drama  3h 21min     8.9     Yes\n",
       "2               Fight Club  1999             Drama  2h 19min     8.9     Yes\n",
       "5            The Godfather  1972      Crime, Drama  2h 55min     9.2      No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_filter = calc_entropy(criteria=movie_history.Rating > 8.8,target='Watched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(MID.40) Here we pick the attribute *Rating* with the condition *Rating > 8.8* and we get a result of 2 watched movies and 1 unwatched movies, and an entropy of 0.92, which is less than what we saw in the previous example but still quite a random segmentation. Let's see another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (Randomness): 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>2h 55min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once upon a time / America</td>\n",
       "      <td>1984</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>3h 49min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Title  Year         Genre    Length  Rating Watched\n",
       "5               The Godfather  1972  Crime, Drama  2h 55min     9.2      No\n",
       "7  Once upon a time / America  1984  Crime, Drama  3h 49min     8.4      No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genre_and_year_filter = calc_entropy(criteria=movie_history.Genre.str.contains('Crime'),target='Watched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(MID.50) Here we pick the attribute *Genre* with the condition *Genre = Crime* and we get a result of 0 watched movies and 2 unwatched movies, and an entropy of 0, which is the least random segmentation we have seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Information gain with attribute Genre = Drama is : 0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the information gain (reduction in entropy) \n",
    "#that would result by splitting the data on the chosen attribute (attr).\n",
    "def gain(data, attr, target_attr):\n",
    " \n",
    "    val_freq = {}\n",
    "    subset_entropy = 0.0\n",
    " \n",
    "    # Calculate the frequency of each of the values in the target attribute\n",
    "    for record in data:\n",
    "        if (record[attr] in val_freq):\n",
    "            val_freq[record[attr]] += 1.0\n",
    "        else:\n",
    "            val_freq[record[attr]]  = 1.0\n",
    " \n",
    "    # Calculate the sum of the entropy for each subset of records weighted by \n",
    "    #their probability of occuring in the training set.\n",
    "    for val in val_freq.keys():\n",
    "        val_prob = val_freq[val] / sum(val_freq.values())\n",
    "        data_subset = [record for record in data if record[attr] == val]\n",
    "        subset_entropy += val_prob * entropy(data_subset, target_attr)\n",
    "        print (subset_entropy)\n",
    " \n",
    "    # Subtract the entropy of the chosen attribute from the entropy of the whole\n",
    "    #data set with respect to the target attribute (and return it)\n",
    "    return round((entropy(data, target_attr) - subset_entropy),2)\n",
    " \n",
    "\n",
    "def calc_information_gain_entropy(criteria,attr,attr_name,target):    \n",
    "    print (\"Information gain with attribute \" + attr_name + \" is : \" + str(gain(movie_history[criteria].to_dict('records'),attr, target)))    \n",
    "    return gain(movie_history[criteria].to_dict('records'),attr, target)\n",
    "\n",
    "criteria=movie_history.Genre.str.contains('Drama')\n",
    "criteria=movie_history.Genre.str.contains('Crime')\n",
    "calc_information_gain_entropy(criteria,'Genre','Genre = Drama','Watched')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(MID.60) With these examples we have seen that measuring the entropy helps us determine the degree of randomness of the result. In order to measure how much an attribute improves (decreases) entropy over the whole segmentation it creates, we use a concept called information gain. Information gain measures the change in entropy due to any amount of new information being added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cloaked/76.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot({\n",
    "\"data\": [\n",
    "    Scatter(x=[1, 2, 3, 4], y=[no_filter, genre_filter, rating_filter, genre_and_year_filter])\n",
    "],\n",
    "\"layout\": Layout(\n",
    "    title=\"Entropy\"\n",
    ")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(MID.20) Now let's try to create a model to figure out which attributes are more informative than others. Let's start with *Genre*. When we filter the history by *Genre = Drama* we get 2 watched movies and 2 unwatched movies. So there is a 50-50 chance of getting an expected result when we pick *Genre = Drama*, which is a highly random prediction. Let's try another attribute *Rating*. When we filter the history by *Rating > 8.8* we get 2 watched movies and 1 unwatched movie, which is a less random result. Let's try a combination of *Genre = Drama AND Year > 1995*. In this case we get 2 watched movies and no unwatched movies, which is the least random result of the attributes that we tested. So, by measuring the randomness of the target values within the dataset, we can determine how informative an attribute is, based how much it reduces the randomness of the target values within the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(MID.30) We can measure randomness using the concept of entropy. Entropy is defined as the following measure of probability : \n",
    "$$entropy = - p_1 log (p_1) - p_2 log (p_2) - ...$$\n",
    "Where $p_1$, in this example, is the probability of the target variable *Watched = Yes* and $p_2$ is the probability of the target variable *Watched = No* in the set of target values produced across the dataset. So in this case where we had used attributes of *Genre = Drama AND Year > 1995*, the result was 2 watched movies and 0 unwatched movies. Which means probability(Watched = Yes) = 1; hence entropy = 1*log(1) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Google](https://www.google.com)\n",
    "> ###Quote\n",
    "$x=y$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(MID.30) An entropy of 1 denotes the most randomness, while an entropy of 0 means least randomness. So this formula can help us determine how much an attribute decreases entropy of the segmentation it creates. This is also called *information gain* which measures the the change in entropy. Hence, we would want attributes that drive the highest information gain when we are trying to predict a target value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Decision trees are an important concept due to their ability to learn to classify individual records in a dataset. They are used in many areas, from typical marketing scenarios such as targeting to airplane autopilots and medical diagnoses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is essentially a series of if-then statements, which when applied to a record in a dataset, results in the classification of thar record. So in our example, the program that you create from a decision tree will be able to predict the likelihood of the person watching a movie from the history of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At every step of the decision tree, the next most informative attribute is selected to divide the dataset according to some predefined criteria. One of the most popular approaches uses the concept of entropy to calculate which attrubute is best to use for dividing the data into subgroups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christopher Roach: Building Decision Trees in Python http://www.onlamp.com/pub/a/python/2006/02/09/ai_decision_trees.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
